  近年来，多个行业创新人工智能技术应用场景，银行智能机器人、虚拟主持人等为社会公众提供了越来越多便捷、智能的服务。然而，也有不法分子通过“AI拟声”“AI换脸”，融合他人面孔和声音制作虚假图像和音视频，仿冒他人身份实施诱骗受害者转账等犯罪行为。这类诈骗方式变化多样、难以分辨，消费者容易落入骗局。专家提示广大消费者，要警惕利用AI技术实施的诈骗行为，保护个人及家庭财产安全。  国家金融监督管理总局发布的消费者权益保护风险提示中介绍，利用AI技术实施诈骗主要有“拟声”“换脸”两种手段，即通过模拟他人声音或形象骗取信任，进而诈骗钱财。不法分子通常先以“网店客服”“营销推广”“招聘兼职”“婚恋交友”等为借口，通过微信、QQ、电话等方式联系消费者，采集声音或面部信息。再利用“拟声”“换脸”等技术合成消费者的虚假音频或视频、图像，以借钱、投资、紧急救助等借口诱导其亲友转账汇款，或提供银行账户密码等敏感信息，随后立即转移资金。此外，不法分子还可能对明星、专家、官员等音视频进行人工合成，假借其身份传播虚假信息，从而实现诈骗目的。  专家表示，网络渠道“眼见”不一定为实。“拟声”“换脸”等合成技术的一大特点是“以假乱真”，不法分子可以利用此类技术轻易伪装成他人，并通过快速筛选目标人群、精准定制诈骗脚本，实施诈骗。因此，在涉及资金往来时，一个“声音很熟的电话”、一段“貌似熟人的视频”都可能是不法分子的诈骗套路，消费者应提高警惕。  为保护广大金融消费者合法权益，国家金融监督管理总局厦门监管局提示广大消费者，转账汇款务必核验对方身份。对自称的“亲友”“熟人”线上发来的消息，若包含转账汇款、提供个人信息、提供短信验证码等请求，应保持高度警惕，采取多种方式确认对方身份。专家介绍，“AI拟声”“AI换脸”包装作伪后的通话和视频虽然能逼真地模仿原始人物的语言和行为，但仍然存在破绽，例如眨眼频率过低、眼睛移动不协调、面部表情不自然、唇形不匹配、语句不连贯等。如果在与亲友视频语音沟通中发现上述异常，消费者应立即警觉起来。在无法确认对方身份时，应尽量避免转账操作。  此外，消费者应提高个人信息保护意识，尽量避免在互联网过多暴露个人照片、声音、视频等信息，要对需要录入个人信息的非正规软件特别警惕。在开启“定位服务”、输入“身份证号”或是录入“人脸识别信息”“指纹识别信息”等个人生物信息时，一定要慎之又慎；发现APP过度、强制收集个人信息时及时向有关部门投诉举报。妥善设置个人社交账户的浏览权限，不过度公开或分享涉及个人信息的动图、视频等，不轻易向陌生人开启手机屏幕共享。（记者 屈信明）