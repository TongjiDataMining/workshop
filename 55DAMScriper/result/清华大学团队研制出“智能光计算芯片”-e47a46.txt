  新华社北京4月12日电（记者魏梦佳）传统硅基电子计算在后摩尔时代面临算力与功耗的双重桎梏，难以支撑人工智能大模型的发展与应用。近日，清华大学研究团队首创了一种干涉—衍射分布式广度光计算架构，并研制出高算力、高能效的智能光计算芯片，可实现每秒每焦耳160万亿次运算的通用智能计算，为大模型通用智能计算探索了新路径。该研究于12日发表于国际学术期刊《科学》。  以光波为载体进行智能计算，具备高速、低功耗等特性。然而，现有智能光计算局限于简单的字符分类、图像处理等。其痛点是光的高性能计算潜力受困于电子计算架构，计算规模受限，无法满足复杂智能计算的需求。  针对大规模智能光计算难题，清华大学电子工程系方璐课题组、信息科学技术学院院长戴琼海院士课题组，摒弃了传统电子深度计算范式，构建了智能光计算的通用传播模型，首创了名为Taichi（意为“太极”）的干涉—衍射分布式广度光计算架构。基于此创新架构，课题组进一步探索干涉光与衍射光的优势特性，又研制出干涉—衍射异构集成智能光计算芯片。  论文第一作者、清华大学电子系博士生徐智昊介绍，与国际上高性能人工智能芯片相比，“太极”芯片的系统整体能量效率提升了3个数量级，可将复杂智能任务拆分为多通道高并行的子任务，赋能光计算实现自然场景千类对象识别、跨模态内容生成等人工智能复杂任务。  “光的物理特性启发了智能光计算新思想，让我们创造出不同于电子深度计算的分布式广度光计算新架构。虽然灵感源于光子，但这一架构同样可为广泛成熟的电子计算平台注入新活力。”方璐表示，在大模型通用人工智能蓬勃发展的时代，希望“太极”未来为大模型训练推理、自主智能无人系统、通用人工智能等提供算力支撑，为高性能计算提供新架构和新路径。  据悉，目前该团队正与相关机构洽谈，建设算力实验室，以期用智能光计算芯片支撑大模型训练与推理、通用人工智能等人工智能研究与应用。